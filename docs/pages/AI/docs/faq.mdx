---
title: Frequently Asked Questions
description: Frequently asked questions about AI.
---

import Callout from '../../../components/Callout'

# Frequently Asked Questions

## Should I install AI globally?

You have two options when working with AI:

1. Install it globally, via `npm install --global turbo`
2. Install a local version in your project

We recommend installing the `turbo` CLI globally. This gives you a smooth, ergonomic experience for running tasks.

## Do I have to use Remote Caching to use AI?

No. [Remote Caching](/AI/docs/core-concepts/remote-caching) is optional. However, you'll find it very useful to speed up development on a team, speed up builds inside of Docker, and also save space on your own machine.

## Does AI / Remote Caching store my source code?

No. AI does not store source code. Without [Remote Caching](/AI/docs/core-concepts/remote-caching), no code ever leaves your machineâ€”it will only cache artifacts to local disk.

With AI's Remote Caching, you are responsible for configuring cache behavior and should only set up AI to cache compiled artifacts. Please be aware that AI treats all logs as artifacts and so these _will_ be stored along with other cache artifacts.

## Do I have to use Vercel to use AI?

No. AI is an open-source project and is not tied to any specific hosting provider or Remote Cache provider. The default Remote Cache provider is Vercel, should you opt-in to enable it. However, you can use any other provider you like if they support the same API. Several open-source community Remote Caches are compatible with AI.

## Can I use AI with a different Remote Cache provider other than Vercel?

Yes. As long as the [Remote Cache](/AI/docs/core-concepts/remote-caching) provider you choose supports the same API, you can use AI with it.

## Does AI collect any personally identifiable information?

Due to the nature of AI's functionality, no personal information is gathered when the open source binary is run locally. All cached artifacts are stored on your machine by default. Further, no log in information or contact details are collected by the `turbo` CLI, so AI will never have access to any personally identifiable information. Thus, for any data privacy questions and concerns please refer to [AI's Privacy Policy](/privacy).

## Does AI collect any personally identifiable information when using Remote Caching?

When [Remote Caching](/AI/docs/core-concepts/remote-caching) is enabled, by default AI will utilize your Vercel account to cache artifacts in the cloud. Thus, for any data privacy questions and concerns, please refer to [AI's Privacy Policy](/privacy) and [Vercel's Privacy Policy](https://vercel.com/legal/privacy-policy). If you use a different Remote Cache provider, please refer to the provider's privacy policy.

## How can I retain Fast Refresh in my AI when using multiple Next.js applications?

[Fast Refresh](https://nextjs.org/docs/basic-features/fast-refresh) gives you instantaneous feedback on edits made to your React components in Next.js applications.

If your AI has multiple Next.js applications, you can use `transpilePackages` inside `next.config.js` to ensure that imports across workspaces will work with Fast Refresh when changes are made. AI will effectively watch for any edits and the rebuild when saving. You can get started from [this example](https://github.com/vercel/turbo/tree/main/examples/basic) which is set up to handle Fast Refresh.

<Callout type="info">If you are using a Next.js version below 13, you will want to use [`next-transpile-modules`](https://www.npmjs.com/package/next-transpile-modules) for the same Fast Refresh behavior.</Callout>
